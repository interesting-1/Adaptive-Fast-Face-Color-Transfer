# 《自适应的快速人脸肤色转移》阅读报告
姓名：吴侃
学号：14348134
邮箱：wkcn@live.cn

## 前言

我阅读的论文的标题为《自适应的快速人脸肤色转移》，这篇论文的作者为魏玮、马军福。这篇论文提出了一种能够自适应、并且快速的人脸肤色转移方法，即将源图像中的人脸肤色转移到目标图像的人脸上，使目标图像的人脸肤色和源图像中的肤色比较相近。我在阅读论文后，对论文提到的算法进行了复现，发现论文中的算法存在瑕疵，没有达到论文中那么理想的效果。为此，我对论文中的算法错误进行更正，提出了改进方法，我也提出了一种论文展望中的“同时处理多幅人脸图像”算法。

## 内容

人脸肤色转移技术属于颜色迁移领域中的一个应用。颜色迁移的实质是“在不破坏目标图像纹理的条件下，将源图像的色彩信息传递给目标图像，使变换后的目标图像具有和源图像相似的色彩特性”。
人脸肤色转移即让目标图像中的人脸肤色尽可能地和源图像中的人脸肤色相近，同时保留人脸的细节。

## 创新点 

我把《自适应的快速人脸肤色转移》论文中的方法的创新点归为两点：有针对性、自适应。

1. 有针对性

	论文中提到了Reinhard等人提出的“彩色图像间颜色迁移”算法，这种算法利用颜色全局信息对整体图像进行颜色迁移。而在肤色迁移问题中，像人的头发、眼睛、嘴巴等颜色是不需要进行变换的，变换的部分只是人的皮肤颜色。在一些相片中，除了人之外还存在背景，使得整个图片的色彩信息变得丰富，但背景也是不需要处理的。本篇论文中的肤色迁移方法，首先选出了图片中的属于肤色的像素，再对这些肤色像素进行变换，避免了对非肤色的转换，针对性强。

2. 自适应

	论文中提到的检测肤色像素的方法具有自适应性，即对不同光照、不同肤色的人的相片，都能比较好地检测出属于肤色的像素。主要体现在作者将检测肤色分为了粗提取、细提取两个阶段。粗提取阶段，在YCbCr颜色空间上粗略地提取出人脸肤色像素点，这一个步骤对误识别为肤色有较大的容忍度；细提取阶段，在Lab颜色空间下，对“可能是肤色的像素点”进行a通道、b通道进行颜色频率统计，这里利用了作者发现的一个规律：“根据600份不同纯肤色数据统计得出，在纯肤色区域各分量对应直方图最大值点的下标为中心，左右两边的对应的面积之差不会超过两边界中最大高度的2倍”。作者根据这个规律设计了一个收敛算法，使用这个算法可以进一步检测出纯肤色区域，这也是细提取阶段的关键方法。
论文中的自适应方法，启发了我思考不同光照环境下，基于颜色进行物体检测的问题，我可以先进行较广颜色范围内的粗提取，再利用颜色分布对粗提取的结果进行细提取。自适应方法和我现在做的空中机器人比赛，基于颜色使用逻辑回归方法检测地面机器人的工作很相关，我可以把自适应方法应用到我的比赛工作中。与此同时，我在比赛中用到的逻辑回归方法，在不同的光照环境下，都能的到较好的效果，我也可以应用逻辑回归方法来改进本篇文章论文的算法。

## 算法流程

论文中的算法分为4个步骤，分别为肤色区间初次聚类（粗提取）、肤色区间的精确聚类（细提取）、肤色转换、颜色矫正。

### 1. 肤色区间的初次聚类

#### 过程：

将图像转换到YCbCr空间。
如果输入像素的颜色落入$$Cr\in[133,173]$$且$$Cb\in[77,127]$$中，就认为该点属于肤色像素。
用0,1矩阵分别标注出源图像和目标图像的某个像素是否被认为是肤色(注意这里是“被认为是肤色”，即被选出的像素不一定是肤色，而是有很大概率可能是肤色)。

####  理论依据：
作者使用了Chai D和Ngan K N在论文《Locating facial region of a head-and-shoulders colo rimage》提出的方法，这个方法是肤色检测方面著名且比较快速的方法，在我们做“人脸检测”项目中也尝试了这种方法。

### 2. 肤色区间的精确聚类

#### 过程：

##### 2.1 将图像转换到Lab颜色空间
引用：http://blog.csdn.net/carson2005/article/details/7200440
同RGB颜色空间相比，Lab是一种不常用的色彩空间。它是在1931年国际照明委员会（CIE）制定的颜色度量国际标准的基础上建立起来的。1976年，经修改后被正式命名为CIELab。它是一种设备无关的颜色系统，也是一种基于生理特征的颜色系统。这也就意味着，它是用数字化的方法来描述人的视觉感应。Lab颜色空间中的L分量用于表示像素的亮度，取值范围是[0,100],表示从纯黑到纯白；a表示从红色到绿色的范围，取值范围是[127,-128]；b表示从黄色到蓝色的范围，取值范围是[127,-128]。下图所示为Lab颜色空间的图示；
![](lab.gif)
##### 2.2 统计a, b通道颜色频率

分别对源图像和目标图像中可能是肤色的像素点，统计它们在a, b通道的颜色频率。分别存储为数组Sa[256], Sb[256], Ta[256], Tb[256].
		
比如: Sa[2]代表源图像被认为是肤色且a通道值为2的像素点个数，Tb[4]代表目标图像被认为是肤色且b通道值为4的像素点个数。

##### 2.3 求a, b分量纯肤色收敛区间

需要求出源图像a、b分量纯肤色收敛区域$$[SaB_g, SaE_d]$$, $$[SbB_g, SbE_d]$$, 以及目标图像a、b分量纯肤色收敛区域$$[TaB_g, TaE_d]$$, $$[TbB_g, TbE_d]$$.

以求$$[SaB_g, SaE_d]$$收敛区域为例：
（注：原文的算法描述有误，这里我重新描述这个算法）
###### a. 找出使Sa取得最大值的数组下标Si 
###### b. 另$$t_1 = Si - 1, t_2 = Si + 1$$
###### c. 求$$t_1$$到Si的总像素个数$$S_1$$，　以及Si到$$t_2$$的总像素个数$$S_2$$ 
###### d. 若$$|S_1 - S_2| > 2 \times max(Sa[t_1], Sa[t_2])或Sa[t_1] = 0或Sa[t_2] = 0$$, 收敛区域确定为$$[t_1, t_2]$$, 否则：
$$t_1 -= 1, t_2 += 1$$, 若$$t_1$$和$$t_2$$都没越界，跳到步骤c.　否则，收敛区域为$$[max(0, t_1), min(255, t_2)]$$

代码实现：
``` python
def get_border(Sa):
    si = np.argmax(Sa)
    t1 = si - 1
    t2 = si + 1
    diff = 0
    while t1 >= 0 and t2 <= 255: 
        diff += (Sa[t1] - Sa[t2])
        if abs(diff) > 2 * max(Sa[t1], Sa[t2]) or Sa[t1] == 0 or Sa[t2] == 0:
            return [t1, t2]
        t1 -= 1
        t2 += 1
    t1 = max(0, t1)
    t2 = min(255, t2)
    return [t1, t2]

```
其他收敛区域同理可得。

#### 理论依据：

作者发现纯肤色区域（去除人脸杂色，如嘴唇、眼睛、眉毛）后的a, b分量的数据分布呈对称的单峰分布，并且这种单峰走势陡峭。根据600份不同纯肤色数据统计得出，在纯肤色区域各分量对应直方图最大值点的下标为中心，左右两边的对应的面积之差不会超过两边界中最大高度的2倍。

## 与课本知识的关系(同，区别)

## 本质
非线性颜色空间

## 算法复现

## 论文的缺点

## 改进 
连通域

## 感受

## 附录
逻辑回归
